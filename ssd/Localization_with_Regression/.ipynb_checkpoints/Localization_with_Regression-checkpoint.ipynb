{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "m5YBsdeoakjv"
   },
   "source": [
    "# Object Detection with Bounding Box Regression\n",
    "\n",
    "This notebook will demonstrate some of the basic steps in object detection. Bounding box regression, as the name suggests, makes a regressor model which directly outputs the bounding box coordinates given an image.\n",
    "\n",
    "This concept has been internal to object detectors like [YOLO](https://arxiv.org/abs/1506.02640).\n",
    "\n",
    "Note: If you are running this notebook on Colab itself, I insist you turn on the GPU runtime. Go to **Tools ~> Runtime ~> Change runtime type ~> Hardware Accelerator ~> Select \"GPU\"**\n",
    "\n",
    "Let's Start!\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TWtbHg3UddHf"
   },
   "source": [
    "\n",
    "## 1) Importing the packages\n",
    "\n",
    "We import TensorFlow and Keras along with our beloved NumPy. We print the TensorFlow version we're using.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "VTg_2ZBqFM2C",
    "outputId": "f0192e4c-ca8b-4769-c0b4-ee86e966a60f"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n",
      "/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.10.1\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import backend as K\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "print( tf.VERSION )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xyVzlExRduu-"
   },
   "source": [
    "## 2) Downloading the data from GitHub\n",
    "\n",
    "We need to download our dataset from the [Dataset_Archives](https://github.com/shubham0204/Dataset_Archives) repo where I have hosted a ZIP file of the dataset. The original dataset hails from [Kaggle.com](https://www.kaggle.com) as [Image Localization Dataset](https://www.kaggle.com/mbkinaci/image-localization-dataset) by [Muhammed Buyukkinaci](https://www.kaggle.com/mbkinaci).\n",
    "\n",
    "Also, we install the [xmltodict](https://pypi.org/project/xmltodict/) package from PyPI which will be useful to parse the XML files containing the bounding box annotations.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "id": "-dIf16k6FT68",
    "outputId": "dd17d936-7691-4a53-ad21-98bc92028e9b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting xmltodict\n",
      "  Downloading https://files.pythonhosted.org/packages/28/fd/30d5c1d3ac29ce229f6bdc40bbc20b28f716e8b363140c26eff19122d8a5/xmltodict-0.12.0-py2.py3-none-any.whl\n",
      "Installing collected packages: xmltodict\n",
      "Successfully installed xmltodict-0.12.0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "!pip install xmltodict\n",
    "\n",
    "#import requests, zipfile, io\n",
    "\n",
    "#r = requests.get( 'https://github.com/shubham0204/Dataset_Archives/blob/master/image-localization-dataset.zip?raw=true' ) \n",
    "#z = zipfile.ZipFile(io.BytesIO(r.content))\n",
    "#z.extractall()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "b28zal0_fEqi"
   },
   "source": [
    "## 3) Defining useful variables\n",
    "\n",
    "Below are some variables which help us in training and preprocessing steps.\n",
    "\n",
    "1.   `input_dim` : The dimensions of input image.\n",
    "2.   `num_classes` : The number of classes we need to predict.\n",
    "3.   `pred_vector_length` : This will be the length of the final output of our CNN. The vector will consists of 4 bounding box coordinates and 3 class probabilities ( 4 + 3 = 7 ).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JMVxJEhUZ2HQ"
   },
   "outputs": [],
   "source": [
    "\n",
    "input_dim = 228\n",
    "num_classes = 3\n",
    "pred_vector_length = 4 + num_classes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2DERx3xbf8zH"
   },
   "source": [
    "## 4) Parsing the images from the dataset\n",
    "\n",
    "We prepare a list of all the files under `training_images` folder which have a `*.jpg` extension ( image files ) using `glob`. We resize them to the `input_dim` and normalize them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bP8pq3CFFW-5"
   },
   "outputs": [],
   "source": [
    "\n",
    "from PIL import Image , ImageDraw\n",
    "import os\n",
    "import glob\n",
    "\n",
    "images = []\n",
    "image_paths = glob.glob( 'training_images/*.jpg' )\n",
    "for imagefile in image_paths:\n",
    "    image = Image.open( imagefile ).resize( ( input_dim , input_dim ))\n",
    "    image = np.asarray( image ) / 255.0\n",
    "    images.append( image )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Kgu_4WTPggsO"
   },
   "source": [
    "## 5) Parsing the bounding box annotations\n",
    "\n",
    "We parse all XML files under the `training_images` folder. These annotations are in the popular `PASCAL-VOC` format. We extract the four bounding box coordinates and normalize them using `input_dim`. Also, we extract the class labels from those files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_sUew-O2FaSZ"
   },
   "outputs": [],
   "source": [
    "\n",
    "import xmltodict\n",
    "import os\n",
    "\n",
    "bboxes = []\n",
    "classes_raw = []\n",
    "annotations_paths = glob.glob( 'training_images/*.xml' )\n",
    "for xmlfile in annotations_paths:\n",
    "    x = xmltodict.parse( open( xmlfile , 'rb' ) )\n",
    "    bndbox = x[ 'annotation' ][ 'object' ][ 'bndbox' ]\n",
    "    bndbox = np.array([ int(bndbox[ 'xmin' ]) , int(bndbox[ 'ymin' ]) , int(bndbox[ 'xmax' ]) , int(bndbox[ 'ymax' ]) ])\n",
    "    bndbox2 = [ None ] * 4\n",
    "    bndbox2[0] = bndbox[0]\n",
    "    bndbox2[1] = bndbox[1]\n",
    "    bndbox2[2] = bndbox[2]\n",
    "    bndbox2[3] = bndbox[3]\n",
    "    bndbox2 = np.array( bndbox2 ) / input_dim\n",
    "    bboxes.append( bndbox2 )\n",
    "    classes_raw.append( x[ 'annotation' ][ 'object' ][ 'name' ] )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IHvyZGlYhMYB"
   },
   "source": [
    "\n",
    "## 6) Preparing the final datasets\n",
    "\n",
    "Our input will be an array of all the images we parsed earlier. The target output will be a concatenation of two arrays i.e the bounding box coordinates and the onehot class labels.\n",
    "\n",
    "Using scikit-learn's `train_test_split` method, we split our dataset in training and validation datasets.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "rYl6unq-Fc3S",
    "outputId": "8dcc2d01-fb91-4d42-dee0-ad5901dec40a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(186, 228, 228, 3)\n",
      "(186, 7)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "boxes = np.array( bboxes ) \n",
    "encoder = LabelBinarizer()\n",
    "classes_onehot = encoder.fit_transform( classes_raw )\n",
    "\n",
    "Y = np.concatenate( [ boxes , classes_onehot ] , axis=1 )\n",
    "X = np.array( images )\n",
    "\n",
    "print( X.shape ) \n",
    "print( Y.shape )\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split( X, Y, test_size=0.1 )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Cp5mYj7Ylauo"
   },
   "source": [
    "## 7) Defining the loss function and evaluation metrics\n",
    "\n",
    "First, we define a method which calculates the intersection over union ( IOU ) of two bounding boxes. In the `custom_loss`, we first calculate Mean Squared Error of the target and predicted bounding boxes. Next, we calculate the IOU loss which is $1 - iou$.\n",
    "\n",
    "Hence, our final loss function is like,\n",
    "\n",
    "$\\Large L( y , y' ) = MSE( y, y') + ( 1 - IOU( y , y' ))$\n",
    "\n",
    "Also, we use IOU as a validation metric to evaluate the model's performance on the testing dataset.\n",
    "\n",
    "**Note: The loss function is a custom implementation. IOU is mostly used as a metric and not in the loss function.**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NPuyqOpQhPiO"
   },
   "outputs": [],
   "source": [
    "\n",
    "input_shape = ( input_dim , input_dim , 3 )\n",
    "dropout_rate = 0.5\n",
    "alpha = 0.2\n",
    "\n",
    "def calculate_iou( target_boxes , pred_boxes ):\n",
    "    xA = K.maximum( target_boxes[ ... , 0], pred_boxes[ ... , 0] )\n",
    "    yA = K.maximum( target_boxes[ ... , 1], pred_boxes[ ... , 1] )\n",
    "    xB = K.minimum( target_boxes[ ... , 2], pred_boxes[ ... , 2] )\n",
    "    yB = K.minimum( target_boxes[ ... , 3], pred_boxes[ ... , 3] )\n",
    "    interArea = K.maximum( 0.0 , xB - xA ) * K.maximum( 0.0 , yB - yA )\n",
    "    boxAArea = (target_boxes[ ... , 2] - target_boxes[ ... , 0]) * (target_boxes[ ... , 3] - target_boxes[ ... , 1])\n",
    "    boxBArea = (pred_boxes[ ... , 2] - pred_boxes[ ... , 0]) * (pred_boxes[ ... , 3] - pred_boxes[ ... , 1])\n",
    "    iou = interArea / ( boxAArea + boxBArea - interArea )\n",
    "    return iou\n",
    "\n",
    "def custom_loss( y_true , y_pred ):\n",
    "    mse = tf.losses.mean_squared_error( y_true , y_pred ) \n",
    "    iou = calculate_iou( y_true , y_pred ) \n",
    "    return mse + ( 1 - iou )\n",
    "\n",
    "def iou_metric( y_true , y_pred ):\n",
    "    return calculate_iou( y_true , y_pred ) \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hidqxtGNn0-g"
   },
   "source": [
    "## 8) Making the CNN model\n",
    "\n",
    "We'll use a CNN model which takes in input an image of shape `( input_dim , input_dim , 3 )` and outputs a vector of shape `( 7 , )`.\n",
    "\n",
    "*   The `Conv2D` layers will extract features from the image.\n",
    "*   We'll use `Dropout` and `LeakyReLU` activation layer to avoid overfitting ( the model will then predict the same bounding boxes for all images ).\n",
    "*   The `Dense` layers will be trained to output the final bounding boxes.\n",
    "\n",
    "We use a small learning rate of 0.0001 so that the learning doesn't stop. Also, we pass the `iou_metric` in the `model.compile()` method.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 139
    },
    "colab_type": "code",
    "id": "SITou1wjFwPi",
    "outputId": "a981b10a-8e60-4f2a-c90e-49e97bcd9d9a"
   },
   "outputs": [],
   "source": [
    "\n",
    "model_layers = [       \n",
    "\tkeras.layers.Conv2D(16, kernel_size=(3, 3), strides=1, input_shape=input_shape),\n",
    "    keras.layers.LeakyReLU( alpha=alpha ) ,\n",
    "    keras.layers.Conv2D(16, kernel_size=(3, 3), strides=1 ),\n",
    "    keras.layers.LeakyReLU( alpha=alpha ) ,\n",
    "    keras.layers.MaxPooling2D( pool_size=( 2 , 2 ) ),\n",
    "\n",
    "    keras.layers.Conv2D(32, kernel_size=(3, 3), strides=1),\n",
    "    keras.layers.LeakyReLU( alpha=alpha ) ,\n",
    "    keras.layers.Conv2D(32, kernel_size=(3, 3), strides=1),\n",
    "    keras.layers.LeakyReLU( alpha=alpha ) ,\n",
    "    keras.layers.MaxPooling2D( pool_size=( 2 , 2 ) ),\n",
    "\n",
    "    keras.layers.Conv2D(64, kernel_size=(3, 3), strides=1),\n",
    "    keras.layers.LeakyReLU( alpha=alpha ) ,\n",
    "    keras.layers.Conv2D(64, kernel_size=(3, 3), strides=1),\n",
    "    keras.layers.LeakyReLU( alpha=alpha ) ,\n",
    "    keras.layers.MaxPooling2D( pool_size=( 2 , 2 ) ),\n",
    "\n",
    "    keras.layers.Conv2D(128, kernel_size=(3, 3), strides=1),\n",
    "    keras.layers.LeakyReLU( alpha=alpha ) ,\n",
    "    keras.layers.Conv2D(128, kernel_size=(3, 3), strides=1),\n",
    "    keras.layers.LeakyReLU( alpha=alpha ) ,\n",
    "    keras.layers.MaxPooling2D( pool_size=( 2 , 2 ) ),\n",
    "\n",
    "    keras.layers.Conv2D(256, kernel_size=(3, 3), strides=1),\n",
    "    keras.layers.LeakyReLU( alpha=alpha ) ,\n",
    "    keras.layers.Conv2D(256, kernel_size=(3, 3), strides=1),\n",
    "    keras.layers.LeakyReLU( alpha=alpha ) ,\n",
    "    keras.layers.MaxPooling2D( pool_size=( 2 , 2 ) ),\n",
    "\n",
    "    keras.layers.Flatten() , \n",
    "\n",
    "    keras.layers.Dense( 1240 ) , \n",
    "    keras.layers.LeakyReLU( alpha=alpha ) ,\n",
    "    keras.layers.Dense( 640 ) , \n",
    "    keras.layers.LeakyReLU( alpha=alpha ) ,\n",
    "    keras.layers.Dense( 480 ) , \n",
    "    keras.layers.LeakyReLU( alpha=alpha ) ,\n",
    "    keras.layers.Dense( 120 ) , \n",
    "    keras.layers.LeakyReLU( alpha=alpha ) ,\n",
    "    keras.layers.Dense( 62 ) , \n",
    "    keras.layers.LeakyReLU( alpha=alpha ) ,\n",
    "\n",
    "    keras.layers.Dense( pred_vector_length ),\n",
    "    keras.layers.LeakyReLU( alpha=alpha ) ,\n",
    "]\n",
    "\n",
    "model = keras.Sequential( model_layers )\n",
    "model.compile(\n",
    "\toptimizer=keras.optimizers.Adam( lr=0.0001 ),\n",
    "\tloss=custom_loss,\n",
    "    metrics=[ iou_metric ]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_PwqHt-YpP8W"
   },
   "source": [
    "## 9) Training the model\n",
    "\n",
    "We finally train the model with the validation dataset and save it to the disk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "kqYpnDhlIiJg",
    "outputId": "70f26d13-7191-451a-ce81-8f52edb5f19c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 167 samples, validate on 19 samples\n",
      "Epoch 1/200\n",
      " 63/167 [==========>...................] - ETA: 23s - loss: 1.0963 - iou_metric: 0.1278"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-6ce7633ea27d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mx_test\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m200\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m )\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1361\u001b[0m           \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1362\u001b[0m           \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1363\u001b[0;31m           validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1364\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1365\u001b[0m   def evaluate(self,\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/tensorflow/python/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, inputs, targets, sample_weights, batch_size, epochs, verbose, callbacks, val_inputs, val_targets, val_sample_weights, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    262\u001b[0m           \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    263\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 264\u001b[0;31m         \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    265\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    266\u001b[0m           \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2912\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_callable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeed_arrays\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_symbols\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msymbol_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2913\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2914\u001b[0;31m     \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2915\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_fetch_callbacks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2916\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1380\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1381\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1382\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1383\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1384\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "model.fit( \n",
    "    x_train ,\n",
    "    y_train , \n",
    "    validation_data=( x_test , y_test ),\n",
    "    epochs=200 ,\n",
    "    batch_size=3 \n",
    ")\n",
    "\n",
    "model.save_weights( 'pretrained_weights.h5')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Z-JywIONpb6W"
   },
   "source": [
    "## 10) Testing the model on test images\n",
    "\n",
    "The following code will predict bounding boxes for some unseen images, draw them on the image using `ImageDraw` and then save them to a folder ( created with `mkdir` command )."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "Qcn3zdf-I5yl",
    "outputId": "38381e5a-391e-4d3d-ca17-c7de2e7c2dd2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: created directory 'inference_images'\n"
     ]
    }
   ],
   "source": [
    "\n",
    "!mkdir -v inference_images\n",
    "\n",
    "boxes = model.predict( x_test )\n",
    "for i in range( boxes.shape[0] ):\n",
    "    b = boxes[ i , 0 : 4 ] * input_dim\n",
    "    img = x_test[i] * 255\n",
    "    source_img = Image.fromarray( img.astype( np.uint8 ) , 'RGB' )\n",
    "    draw = ImageDraw.Draw( source_img )\n",
    "    draw.rectangle( b , outline=\"black\" )\n",
    "    source_img.save( 'inference_images/image_{}.png'.format( i + 1 ) , 'png' )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fMysv18NqMMI"
   },
   "source": [
    "## 11) Print the average IOU and class accuracy\n",
    "\n",
    "We will calculate the average IOU score over the validation dataset and also the accuracy of the model in predicting classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "ofgrJJxEOpOk",
    "outputId": "dc2d3f13-3c2c-4b41-eafc-29543537ccbb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean IOU score 0.5800086476915025\n",
      "Class Accuracy is 42.10526315789473 %\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def calculate_avg_iou( target_boxes , pred_boxes ):\n",
    "    xA = np.maximum( target_boxes[ ... , 0], pred_boxes[ ... , 0] )\n",
    "    yA = np.maximum( target_boxes[ ... , 1], pred_boxes[ ... , 1] )\n",
    "    xB = np.minimum( target_boxes[ ... , 2], pred_boxes[ ... , 2] )\n",
    "    yB = np.minimum( target_boxes[ ... , 3], pred_boxes[ ... , 3] )\n",
    "    interArea = np.maximum(0.0, xB - xA ) * np.maximum(0.0, yB - yA )\n",
    "    boxAArea = (target_boxes[ ... , 2] - target_boxes[ ... , 0]) * (target_boxes[ ... , 3] - target_boxes[ ... , 1])\n",
    "    boxBArea = (pred_boxes[ ... , 2] - pred_boxes[ ... , 0]) * (pred_boxes[ ... , 3] - pred_boxes[ ... , 1])\n",
    "    iou = interArea / ( boxAArea + boxBArea - interArea )\n",
    "    return iou\n",
    "\n",
    "def class_accuracy( target_classes , pred_classes ):\n",
    "    target_classes = np.argmax( target_classes , axis=1 ) \n",
    "    pred_classes = np.argmax( pred_classes , axis=1 ) \n",
    "    return ( target_classes == pred_classes ).mean()\n",
    "\n",
    "target_boxes = y_test * input_dim\n",
    "pred = model.predict( x_test )\n",
    "pred_boxes = pred[ ... , 0 : 4 ] * input_dim\n",
    "pred_classes = pred[ ... , 4 : ]\n",
    "\n",
    "iou_scores = calculate_avg_iou( target_boxes , pred_boxes )\n",
    "print( 'Mean IOU score {}'.format( iou_scores.mean() ) )\n",
    "\n",
    "print( 'Class Accuracy is {} %'.format( class_accuracy( y_test[ ... , 4 : ] , pred_classes ) * 100 ))\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "Localization_with_Regression.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
